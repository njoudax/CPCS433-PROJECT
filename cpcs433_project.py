# -*- coding: utf-8 -*-
"""CPCS433-PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FWzWUA-CiO49CH7IEyexRJqoZOe6Ogxv

#CPCS433_Project
"""

# Importing Libraries
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn import metrics
import plotly.express as px
from matplotlib import pyplot
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.ensemble import IsolationForest, RandomForestClassifier

"""## **Load The DataSet**"""

# Loading The Dataset
dataset = pd.read_csv('/content/riceClassification.csv')

# Print The Shape Of Data
dataset.shape

# Print The Data
dataset

# Print The Dataset Info
dataset.info()

"""## **Preprocess The Dataset**

**1. Missing Values**
"""

# Checking For Missing Values
dataset.isnull().sum()

"""There Is No Missing Value In Our DataSet

**2. Duplicated Values**
"""

# Checking For Duplicated Values
print('Number Of Duplicated Values In The Dataset: ', dataset.duplicated().sum())

"""There Is No Duplicated Value In Our DataSet

**3. Class Imbalance**
"""

# Check For Class Imbalance In The Dependent Variable
print (dataset['Class'].value_counts(ascending = True))

"""There Is No Class Imbalance In Our Dependent Variable, We Can See Clearly That The Count Of Class 0 Is 8200, And The Count Of Class 1 Is 9985 Which Shwos A Balance

Here Class 0 Means Jasmine Rice

and Class 1 Means Gonen Rice
"""

# Drop Unneeded Column Like ID
dataset = dataset.drop('id', axis = 1)

"""**4. Handle Outliers**"""

# Using IsolationForest To Detect And Fliter Out Outliers
clf = IsolationForest(random_state=1)
outliers = clf.fit_predict(dataset)
dataset = dataset[outliers == 1]

# Print The Shape After Flitering Outliers
dataset.shape

"""We Can See Clearly number of rows decrees from 18185 to 14779

**5. HeatMap**
"""

# Heatmap To Showcase The Correlation
sns.heatmap(dataset.corr(),cmap = "Purples", annot = True)

"""##Training the model"""

# Split The Values Of Independent Features(X) And Dependent Target(Y)
X = dataset.drop(columns = 'Class', axis = 1)
Y = dataset['Class']

# Splitting The Data Useing Splitting Ratio 70:30
X_train, X_test, Y_train , Y_test = train_test_split(X,Y,test_size = 0.3, random_state = 0 )

"""##Testing the model

**1. Random Foesrt**

**1.1 Accuracy**
"""

RandomForest_model = RandomForestClassifier()
Train_scores, Test_scores = list(), list()

# Fit Data To Random Forest Model
RandomForest_model.fit(X_train, Y_train)
Y_Train_Pred = RandomForest_model.predict(X_train)

# Print The Accuracy Score For Trainign
Train_Accuracy = metrics.accuracy_score(Y_train,Y_Train_Pred)
print ("Train Accuracy : %s" % "{0:.3%}".format(Train_Accuracy))
Train_scores.append(Train_Accuracy)


# Print The Accuracy Score For Testing
Y_Test_Pred = RandomForest_model.predict(X_test)
Test_Accuracy = metrics.accuracy_score(Y_test,Y_Test_Pred)
print ("Test Accuracy : %s" % "{0:.3%}".format(Test_Accuracy))
Test_scores.append(Test_Accuracy)

"""**1.2 Confusion Matrix**"""

# Compute Confusion Matrix
ConfusionMatrix = confusion_matrix(Y_test,Y_Test_Pred)

# Display Confusion Matrix Using A Heatmap
plt.figure(figsize = (8, 6))
sns.heatmap(ConfusionMatrix, annot = True, fmt = "d", cmap = "Purples", cbar = True)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

"""**2. Decision Tree**
**2.1 Accuracy**
"""

dt_classifier = DecisionTreeClassifier(max_depth=5)  # You can change the depth here

# Fit the model on the training data
dt_classifier.fit(X_train, Y_train) # Predict on the testing data
y_pred = dt_classifier.predict(X_test)

# Calculate the accuracy in percentage
accuracy_percentage = accuracy_score(Y_test, y_pred) * 100

# Fit the model on the training data
y_pred2 = dt_classifier.predict(X_train)

# Calculate the accuracy in percentage
accuracy_percentage2 = accuracy_score(Y_train, y_pred2) * 100

# Evaluate the model
print("Accuracy: {:.2f}%".format(accuracy_percentage))

# Evaluate the model
print("Accuracy: {:.2f}%".format(accuracy_percentage2))

"""**2.2 Confusion Matrix**"""